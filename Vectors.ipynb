{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c0a3419b-a32d-4067-b3e6-658ce4b75d1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original text : I am feeling very very happy today!!!..\n"
     ]
    }
   ],
   "source": [
    "text=\"I am feeling very very happy today!!!..\"\n",
    "print(\"Original text :\",text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a51bb178-ffaa-4429-8c06-00464ab70b52",
   "metadata": {},
   "source": [
    "# NLP-Phase1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9be44c0b-b05b-478a-a151-d9586ddf3fcf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lowercase: i am feeling very very happy today!!!..\n"
     ]
    }
   ],
   "source": [
    "# step1 convert \n",
    "text=text.lower()\n",
    "print(\"Lowercase:\",text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "662221f5-580b-4d54-a084-dc3a2d988b2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "without punctuation: i am feeling very very happy today\n"
     ]
    }
   ],
   "source": [
    "#step-2 remove punctuations \n",
    "# we reverse everything except letters and spaces\n",
    "#using re-regular expression\n",
    "import re\n",
    "text=re.sub(r'[^\\w\\s]','',text)\n",
    "print(\"without punctuation:\",text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6e0267d7-e71b-41fc-9d1d-a4a1bb4b4fb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokens: ['i', 'am', 'feeling', 'very', 'very', 'happy', 'today']\n"
     ]
    }
   ],
   "source": [
    "tokens=text.split() #step4: tokentiazation\n",
    "print(\"Tokens:\",tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5b7e03b2-c6da-4034-8f24-e38835777009",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After removing stopwords:  ['feeling', 'happy', 'today']\n"
     ]
    }
   ],
   "source": [
    "#step 4:remove stop word=is are am an the\n",
    "stopwords=[\"i\",\"am\",\"the\",\"are\",\"a\",\"an\",\"very\"]\n",
    "filtered_token=[]\n",
    "for word in tokens:\n",
    "    if word not in stopwords:\n",
    "        filtered_token.append(word)\n",
    "\n",
    "print(\"After removing stopwords: \",filtered_token)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2eea726e-8b3b-4f77-abd1-3f7e07b94556",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After stemming : ['feel', 'happy', 'today']\n"
     ]
    }
   ],
   "source": [
    "def stem(word):\n",
    "    if word.endswith(\"ing\"):\n",
    "        return word[:-3]\n",
    "    return word\n",
    "\n",
    "stemmed_words=[]\n",
    "for word in filtered_token:\n",
    "    stemmed_words.append(stem(word))\n",
    "\n",
    "print(\"After stemming :\",stemmed_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dbb0fdf-1b47-4b71-9636-4ad4d016d67c",
   "metadata": {},
   "source": [
    "# NLP Phase2:words to vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "06cd188c-826c-4368-9d4b-3624487f601f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#why vector ?\n",
    "#because ML only understands numbers\n",
    "#we must convert words into numeric form\n",
    "#Bag of words(Bow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8c20475a-937a-445b-9453-b9860124c9c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer #help text->count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "475f2597-33e5-4471-b578-6250e95c0f4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences=[\n",
    "    \"I am good\",\n",
    "    \"I am fine\",\n",
    "    \"I am sad\",\n",
    "    \"happy today\"\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "dbb59c01-5c88-4d20-bed6-595d836cfb7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#vectorize\n",
    "vectorizer=CountVectorizer() # creating object\n",
    "X=vectorizer.fit_transform(sentences)\n",
    "#learn vocab and convert sentences to numbers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "dcc168fd-3606-4e49-9ffd-b000faa838ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary:  ['am' 'fine' 'good' 'happy' 'sad' 'today']\n"
     ]
    }
   ],
   "source": [
    "print(\"Vocabulary: \",vectorizer.get_feature_names_out())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a3c94575-efe8-4f29-b112-edc79b529977",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vectors:\n",
      "[[1 0 1 0 0 0]\n",
      " [1 1 0 0 0 0]\n",
      " [1 0 0 0 1 0]\n",
      " [0 0 0 1 0 1]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Vectors:\")\n",
    "print( X.toarray())\n",
    "# Each row=sentences\n",
    "# Each coloumn=word\n",
    "#Each value=count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "843d2d96-96c6-4ac6-8253-6f5e819ad549",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary : ['also' 'am' 'and' 'good' 'great' 'is' 'learn' 'learning' 'love' 'machine'\n",
      " 'programming' 'python' 'to' 'with']\n"
     ]
    }
   ],
   "source": [
    "sentences=[\n",
    "    \"i am learning python and python is good\",\n",
    "    \"python is a great programming to learn\",\n",
    "    \"i also love machine learning with python\"\n",
    "]\n",
    "vectorizer=CountVectorizer()\n",
    "X=vectorizer.fit_transform(sentences)\n",
    "print(\"Vocabulary :\",vectorizer.get_feature_names_out())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0b6ec48d-d4ca-433e-9b40-ea50dfaf5206",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matrix :\n",
      "[[0 1 1 1 0 1 0 1 0 0 0 2 0 0]\n",
      " [0 0 0 0 1 1 1 0 0 0 1 1 1 0]\n",
      " [1 0 0 0 0 0 0 1 1 1 0 1 0 1]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Matrix :\")\n",
    "print(X.toarray())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "287c9409-db02-4cd7-957b-ff9d92e0eb75",
   "metadata": {},
   "source": [
    "# TF-IDF->Term frequency -Inverse Document frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "16973d06-0154-43e9-8d32-66c59ad698c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#bag of word treats all word equally\n",
    "#for example= i am learning python python and python\n",
    "# it will assign huge weights to python\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e9f158ae-0ea7-4cde-91ab-fd9adfb842c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "777585c5-2720-45d4-9859-12ed26d43390",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences=[\n",
    "    \"i am learning python and python is good\",\n",
    "    \"python is a great programming to learn\",\n",
    "    \"i also love machine learning with python\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "bad1f599-2a5b-4533-b5c9-2bacba033f26",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer=TfidfVectorizer()\n",
    "X=vectorizer.fit_transform(sentences)\n",
    "#internally it will built vocan and calculate tf but it also calculate idf and multiply tf*idf and generate matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "6516e13a-cb4f-4866-853e-060f63c00d43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary : ['also' 'am' 'and' 'good' 'great' 'is' 'learn' 'learning' 'love' 'machine'\n",
      " 'programming' 'python' 'to' 'with']\n"
     ]
    }
   ],
   "source": [
    "print(\"Vocabulary :\",vectorizer.get_feature_names_out())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "062fc59e-e6f5-43ed-b1df-84654adeaeeb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF-IDF matrix: \n",
      "[[0.         0.42439575 0.42439575 0.42439575 0.         0.32276391\n",
      "  0.         0.32276391 0.         0.         0.         0.50130994\n",
      "  0.         0.        ]\n",
      " [0.         0.         0.         0.         0.45050407 0.34261996\n",
      "  0.45050407 0.         0.         0.         0.45050407 0.26607496\n",
      "  0.45050407 0.        ]\n",
      " [0.45050407 0.         0.         0.         0.         0.\n",
      "  0.         0.34261996 0.45050407 0.45050407 0.         0.26607496\n",
      "  0.         0.45050407]]\n"
     ]
    }
   ],
   "source": [
    "print(\"TF-IDF matrix: \")\n",
    "print(X.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "190677b2-7d56-4699-a1f2-b78aab67979a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# \"am learning python,python and python\"\n",
    "#IDF calculation:\n",
    "#log(total documents/documents containing word)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
